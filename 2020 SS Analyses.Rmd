---
title: "2020 Small Stream Analyses"
author: "Jay Silvanima"
date: "9/12/2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rmarkdown)
```

## Contact:
### James (Jay) Silvanima
Department of Environmental Protection

Watershed Monitoring and Data Management

2600 Blair Stone Road

Tallahassee, Florida 32399-2400

James.Silvanima@dep.state.fl.us

phone:   850-245-8507

fax:        850-245-8554

# __Purpose__

Purpose: Analysis of Florida Stream data generated by the Status Monitoring Program. Created by Jay Silvanima using code developed by Tony Olsen, myself, Chris Sedlacek, Stephanie Sunderman-Barnes, and Liz Miller on 05-07-2021.

Code developed using R version 3.6.2 (2019-12-12), spsurvey version
4.1.0, and FDEPgetdata version 1.4.

This RMarkdown script is based on the R script “2020 SS Script.R” The data used in this example are from 2020.

Load libraries and set working directory or path.

```{r}
# File: 2020 SS Script.R
##Set directory. This is where the outputs will be saved. 
#   Alter to desired location. Use getwd() to determine the directory for
#     your r project.

setwd("C:/R/Status 2020/2020 SS")

# Load libraries for the data analyses

library(FDEPgetdata)
library(spsurvey)
library(sf)
library(ggplot2)
```

## __Load Site Information Data__ 

Load the file SS20_Sites.cvs and create a new data frame from it.

Note that due to the COVID19 pandemic sampling was reduced.  For most zones sampling stopped after the fifth site was sampled.  The goal was to get at least a sample size for thirty for the entire state.

Convert Lat longs from DDMMSS decimal seconds to degress decimal degress for spsurvy functions. Then create a simple features object and convert to Florida albers projection and plot the evaluated sites. The number of sites will be more than that of those actually sampled because many will have excluded due to various reasons.

```{r}

SS.SITES <- read.csv('C:/R/Status 2020/2020 SS/SS20_Sites.csv')
names(SS.SITES)

# Convert to Decimal degrees

deg <- floor(SS.SITES$RANDOM_LATITUDE/10000)
min <- floor((SS.SITES$RANDOM_LATITUDE - deg*10000)/100)
sec <- SS.SITES$RANDOM_LATITUDE - deg*10000 - min*100
SS.SITES$latdd <- deg + min/60 + sec/3600
deg <- floor(SS.SITES$RANDOM_LONGITUDE/10000)
min <- floor((SS.SITES$RANDOM_LONGITUDE - deg*10000)/100)
sec <- SS.SITES$RANDOM_LONGITUDE - deg*10000 - min*100
SS.SITES$londd <- deg + min/60 + sec/3600

# Change londd to negative for correct use in sf.
SS.SITES$londd <- -SS.SITES$londd

# Create sf object and transform to Albers projection for analysis
#  This codes utilizes Coordinate Reference System (CRS/EPSG) Codes.
#  The first crs code (4269) below is for NAD 83 coordinate system the 
#  second crs code (3087) is for Florida albers projection. 
#  More information on these codes is found here: 
#  https://www.nceas.ucsb.edu/sites/default/files/2020-04/OverviewCoordinateReferenceSystems.pdf.

dsgn_SS <- st_as_sf(SS.SITES, coords = c("londd", "latdd"), remove = FALSE,
                    crs = 4269)
dsgn_sf <- st_transform(dsgn_SS, crs = 3087)

# keep xy coords as variables
tmp <- st_coordinates(dsgn_sf)
dsgn_sf$xcoord <- tmp[, "X"]
dsgn_sf$ycoord <- tmp[, "Y"]

# plot sites using sf
plot(st_geometry(dsgn_sf))

```

## ___Determine which sites belong in the target population___

The variables CAN_BE_SAMPLED, EXCLUSION_CATEGORY and EXCLUSION_CRITERIA provide information on the site evaluation results for each site.  Review the information and create target/nontarget (TNT) variable.Create sampled and target (T) / nontarget (NT) variables.  

Adjust sample weights for design as Implemented. 

```{r}

# Site Evaluation

addmargins(table(dsgn_sf$EXCLUSION_CATEGORY, dsgn_sf$CAN_BE_SAMPLED, useNA = 'ifany'))
addmargins(table(dsgn_sf$EXCLUSION_CRITERIA, useNA = 'ifany'))


# create sampled and target (T) / nontarget (NT) variables

dsgn_sf$EXCLUSION_CATEGORY <- as.character(dsgn_sf$EXCLUSION_CATEGORY)
dsgn_sf$EXCLUSION_CATEGORY[dsgn_sf$CAN_BE_SAMPLED == 'Y'] <- 'SAMPLED'
dsgn_sf$EXCLUSION_CATEGORY <- as.factor(dsgn_sf$EXCLUSION_CATEGORY)
levels(dsgn_sf$EXCLUSION_CATEGORY)
dsgn_sf$TNT <- dsgn_sf$EXCLUSION_CATEGORY
levels(dsgn_sf$TNT) <- list(T=c('SAMPLED', 'NO PERMISSION FROM OWNER', 'UNABLE TO ACCESS','OTHERWISE UNSAMPLEABLE','DRY'),
                            NT=c('WRONG RESOURCE/NOT PART OF TARGET POPULATION') )

addmargins(table(dsgn_sf$EXCLUSION_CATEGORY, dsgn_sf$TNT, useNA = 'ifany'))

```

We evaluated 126 stream locations and determined that 12 were non-target, and of the 114 which were target 38 were able to be sampled.


## ___Adjust weights for Design As Implemented___

Per Tony Olsen, “The initial design weights must be adjusted to account for the actual number of sites evaluated. The weight adjustment requires knowing the stream lengths in the sample frame. First, create the framesize using stream kilometers from that 2020 stream design document. The initial design weights are in the column ”NEST1_WT" and the weight adjustment categories are the six reporting units."

Note need frame size here found in design doc for stream site selections. From design document framesize in kilometers = 24,380.196 for entire data frame.

```{r}

# Note need frame size here found in design doc for stream site selections
#  Z:\Chris site selection process\2020 site selections\2020 SS\Florida 2020 stream Design.doc
#  From design document framesize in kilometers = 24,380.196 for entire data frame.

framesize <- c("ZONE 1"=12342.640 ,"ZONE 2"=2212.137, 
                "ZONE 3"=4424.757 ,"ZONE 4"=4211.302,
                "ZONE 5"=1006.819 ,"ZONE 6"=182.541)

# use all evaluated sites to adjust weights
nr <- nrow(dsgn_sf)
dsgn_sf$wgt <- adjwgt(rep(TRUE,nr), dsgn_sf$NEST1_WT, 
                      dsgn_sf$REPORTING_UNIT, framesize=framesize)

# check sum of weights for each reporting unit/basin
addmargins(tapply(dsgn_sf$wgt, dsgn_sf$REPORTING_UNIT, sum))


# This gives the weights for the stream design as implemented in 2020. 
# It must include all evaluated sites as some sites are not in the 
#  target population.

```

## ___Estimate Extent of Stream Kilometers in Target Population___

Since the sample frame includes portions of small stream object segments that do not meet the definition of a small stream, the site evaluation information is used to estimate the small stream kilometers in the target population for entire state and for each of the reporting units/basins.

```{r}

# Estimate Extent Stream Kilometers.
# Since the sample frame includes portions of stream object line segments that do not 
#  meet the definition of a stream, the site evaluation information is used 
#  to estimate the stream kilometers in the target population for entire state and for 
#  each of the reporting units/basins.

sites <- data.frame(siteID = dsgn_sf$PK_RANDOM_SAMPLE_LOCATION, Use=rep(TRUE,nr) )
subpop <- data.frame(siteID = dsgn_sf$PK_RANDOM_SAMPLE_LOCATION,
                     Combined = rep("All Basins", nr), 
                     Basin = dsgn_sf$REPORTING_UNIT) 
dsgn <- data.frame(siteID = dsgn_sf$PK_RANDOM_SAMPLE_LOCATION, 
                   wgt = dsgn_sf$wgt,
                   xcoord = dsgn_sf$xcoord,
                   ycoord = dsgn_sf$ycoord,
                   stratum = dsgn_sf$REPORTING_UNIT)

data.cat <- data.frame(siteID = dsgn_sf$PK_RANDOM_SAMPLE_LOCATION,
                       TNTStatus=dsgn_sf$TNT,
                       EXCLUSION.CATEGORY = dsgn_sf$EXCLUSION_CATEGORY)

ExtentEst <- cat.analysis(sites, subpop, dsgn, data.cat, conf=95)

# write out or export results
write.csv(ExtentEst,file = 'ExtentEst.csv')

```

Of the 24,380.196 stream kilometers in the sample frame, 90.4% are estimated to be in the 
target population.  Also, only 30.0% of the sample frame could actually be sampled. To estimate the percent of the target population that could be sampled, requires that the analysis be restricted to just sites in the target population, i.e., TNT = "T"

```{r}

sites <- data.frame(siteID = dsgn_sf$PK_RANDOM_SAMPLE_LOCATION, Use = dsgn_sf$TNT == "T" )
subpop <- data.frame(siteID = dsgn_sf$PK_RANDOM_SAMPLE_LOCATION,
                     Combined = rep("All Basins", nr), 
                     Basin = dsgn_sf$REPORTING_UNIT) 
dsgn <- data.frame(siteID = dsgn_sf$PK_RANDOM_SAMPLE_LOCATION, 
                   wgt = dsgn_sf$wgt,
                   xcoord = dsgn_sf$xcoord,
                   ycoord = dsgn_sf$ycoord,
                   stratum = dsgn_sf$REPORTING_UNIT)

data.cat <- data.frame(siteID = dsgn_sf$PK_RANDOM_SAMPLE_LOCATION,  
                       EXCLUSION.CATEGORY = dsgn_sf$EXCLUSION_CATEGORY)

ExtentEst_Target <- cat.analysis(sites, subpop, dsgn, data.cat, conf=95)

# write out or export results
write.csv(ExtentEst_Target, file = 'ExtentEst_Target.csv')

# 33.1% of the target population area could be sampled, i.e., 
#  7303.2 kilometers CI(5350.4, 9256.1)

```

## __Load Water Quality Data__

Run function of FDEPgetdata package to pull result data. Insert varible name between parentheses in function call below. The function will pull the water resource for the water resource by year. For example small stream projects during year 2020 the enty would be “‘SS20’”. Entering “‘LL18’,‘LL19’,‘LL20’” for the variable will produce a dataframe for FDEP Status small streams sampled 2018 - 2020. Be sure to enclose in double and single quotes. Water resource acronyms are SS = small streams, LR = large rivers, CN = canals.

For this markdown file we’ll read in the export of the data pull above because the package FDEPgetdata is an internal FDEP package.

```{r}

SS_RSLTS <- read.csv('C:/R/Status 2020/2020 SS/SS20_Results.csv')

# Create new data frame from the one just loaded.

names(SS_RSLTS)

# Determine sample types in file.
addmargins(table(SS_RSLTS$SAMPLE_TYPE, SS_RSLTS$MATRIX, useNA = 'ifany'))

```

## __Load Water Quality Data__

Water quality analyses are based on 38 sites from the results file and must be merged with design information. This merge will remove any result data marked as inappropriate for Status Network analysis (i.e. where pk_random_sample_location contains "B").

```{r}

# Note that have BLANK, BOTTOM and PRIMARY data and matrix types. 
# Only want to use PRIMARY results for population estimation.

keep <- SS_RSLTS$SAMPLE_TYPE == 'PRIMARY' & SS_RSLTS$MATRIX == 'WATER'

# merge with exclusion file
SS_WQ <- merge(as.data.frame(dsgn_sf)[, c("PK_RANDOM_SAMPLE_LOCATION",
                "REPORTING_UNIT", "EXCLUSION_CATEGORY","TNT", "wgt", 
                "londd", "latdd", "xcoord", "ycoord", "TN_NNC", "TP_NNC",
                "DO_Conc")], SS_RSLTS[keep,], 
               by.x = 'PK_RANDOM_SAMPLE_LOCATION', 
               by.y = 'FK_RANDOM_SAMPLE_LOCATION')

# check that have only PRIMARY for Water MATRIX data
addmargins(table(SS_WQ$SAMPLE_TYPE, SS_WQ$MATRIX, useNA = 'ifany'))


```

## __Ammonia Calculation for Threshold__

Calculates total ammonia from single sample criteria

Code chunk written 1/6/2020 by Stephanie Sunderman Barnes. Calculator for total ammonia nitrogen (TAN) single sample criteria. Created using TAN calculator spreadsheet as a guide (accessed 1/3/2020, https://floridadep.gov/dear/water-quality-standards-program/documents/total-ammonia-nitrogen-calculator%C2%A0).

```{r}

##TotAmm.pH = pH used in ammonia calc. If measured pH < 6.5, value used is 6.5. If meas. pH > 9.0, value used is 9.0.
SS_WQ$TotAmm_pH <- ifelse(SS_WQ$pH_Field < 6.5, 6.5, 
                         ifelse(SS_WQ$pH_Field > 9.0, 9.0,SS_WQ$pH_Field))

##TotAmm.temp = water temperature used in ammonia calc. If measured temp < 7 degrees C, value used is 7.
SS_WQ$TotAmm_temp <- ifelse(SS_WQ$Water_Temperature < 7, 7, SS_WQ$Water_Temperature )

##calculate single sample Total Ammonia Criteria using TotAmm.pH and TotAmm.temp							
SS_WQ$TotAmmCrit_SingleSamp <- ifelse(is.na(SS_WQ$TotAmm_pH), NA,
                                     ifelse(is.na(SS_WQ$TotAmm_temp), NA,
                                            (2.5*(0.8876*((0.0278/(1+10^(7.688-SS_WQ$TotAmm_pH)))+(1.1994/(1+10^(SS_WQ$TotAmm_pH-7.688))))*2.126*10^(0.028*(20-(SS_WQ$TotAmm_temp)))))))

##Round result to two decimal places
SS_WQ$TotAmmCrit_SingleSamp <- round(SS_WQ$TotAmmCrit_SingleSamp, digits=2)

##Run analysis similar to NNC using the single sample total ammonia criteria calculated above
### Pass=1 AND Fail=0
SS_WQ$TAmm_Cat<-ifelse((SS_WQ$TotAmmCrit_SingleSamp >= SS_WQ$Ammonia_Total_as_N),1,0)

#########End Ammonia Calculation

```

## __Set up threshold category columns for remainder of analytes__

E_Coli category

```{r}

E_Coli_cat <- cut(SS_WQ$Escherichia_Coli_Quanti_Tray, breaks=c(0,409,10000000), include.lowest=TRUE)
SS_WQ$E_Coli_cat <- E_Coli_cat
SS_WQ$E_Coli_cat <- as.factor(SS_WQ$E_Coli_cat)

```

Old Dissolved Oxygen Category

```{r}

DO_cat_old <- cut(SS_WQ$Oxygen_Dissolved_Field, breaks=c(0,4.999,1000000), include.lowest=TRUE)
SS_WQ$DO_cat_old <- DO_cat_old
SS_WQ$DO_cat_old <- as.factor(SS_WQ$DO_cat_old)

```
pH Category

```{r}

pH_cat <- cut(SS_WQ$pH_Field, breaks=c(0,5.999,8.5,14), include.lowest=TRUE)
SS_WQ$pH_cat <- pH_cat
SS_WQ$pH_cat <- as.factor(SS_WQ$pH_cat)

```

Chlorophyll Category

```{r}

Chlorophyll_cat <- cut(SS_WQ$Chlorophyll_A_Monochromatic, breaks=c(0,20,10000), include.lowest=TRUE)
SS_WQ$Chlorophyll_cat <- Chlorophyll_cat
SS_WQ$Chlorophyll_cat <- as.factor(SS_WQ$Chlorophyll_cat)

```

Calculate Total Nitrogen (TN) as sum of TKN & NO3NO2.

Numeric Nutrient and DO Categories
Note Pass=1 AND Fail=0
Total NNC category = sum of category results for TN, TP, and DO. 
If Tot_cat = 3, sample passed criteria for these 3 parameters.

```{r}


SS_WQ$TN<-(SS_WQ$Kjeldahl_Nitrogen_Total_as_N+SS_WQ$NitrateNitrite_Total_as_N)

SS_WQ$TN_cat<-ifelse((SS_WQ$TN_NNC >= SS_WQ$TN),1,0) 

SS_WQ$TP_cat<-ifelse((SS_WQ$TP_NNC >= SS_WQ$Phosphorus_Total_as_P),1,0)  

SS_WQ$DO_cat<-ifelse((SS_WQ$Oxygen_Dissolved_Percent_Saturation >= SS_WQ$DO_Conc ),1,0)	

SS_WQ$Tot_cat<-(SS_WQ$TN_cat+SS_WQ$TP_cat+SS_WQ$DO_cat)

##### End setting up categories for water quality indicators

nr <- nrow(SS_WQ)
levels(SS_WQ$TNT)

```

## __Continuous Water Quality Indicator Indicator Estimates __

```{r}

sites_WQ <- data.frame(siteID = SS_WQ$PK_RANDOM_SAMPLE_LOCATION, Use = SS_WQ$TNT == "T" )
subpop_WQ <- data.frame(siteID = SS_WQ$PK_RANDOM_SAMPLE_LOCATION,
                        Combined = rep("All Basins", nrow(SS_WQ)), 
                        Basin = SS_WQ$REPORTING_UNIT) 
dsgn_WQ <- data.frame(siteID = SS_WQ$PK_RANDOM_SAMPLE_LOCATION, 
                      wgt = SS_WQ$wgt,
                      xcoord = SS_WQ$xcoord,
                      ycoord = SS_WQ$ycoord,
                      stratum = SS_WQ$REPORTING_UNIT)

# continuous WQ estimates

data.cont.WQ <- data.frame(siteID=SS_WQ$PK_RANDOM_SAMPLE_LOCATION, 
                           SS_WQ[,c('Oxygen_Dissolved_Field','pH_Field','Escherichia_Coli_Quanti_Tray',
                                    'Chlorophyll_A_Monochromatic','Ammonia_Total_as_N','TN','Phosphorus_Total_as_P')])
Water_quality_Cont <- cont.analysis(sites = sites_WQ, subpop = subpop_WQ, 
                               design = dsgn_WQ, data.cont = data.cont.WQ, conf=95)


```

## __Categorical Water Quality Indicator Indicator Estimates __

```{r}

data.cat.wq <- data.frame(siteID = SS_WQ$PK_RANDOM_SAMPLE_LOCATION,
                           Ammonia_Category = SS_WQ$TAmm_Cat,
                           Chlorophyll_Category = SS_WQ$Chlorophyll_cat,
                           TN_Category = SS_WQ$TN_cat,
                           TP_Category = SS_WQ$TP_cat,
                           DO_Category = SS_WQ$DO_cat,
                           TN_TP_DO_Category = SS_WQ$Tot_cat,
                           E_Coli_Category = SS_WQ$E_Coli_cat,
                           pH_Category = SS_WQ$pH_cat)

Water_Quality_Cat <- cat.analysis(sites = sites_WQ, subpop = subpop_WQ, 
                             design = dsgn_WQ, data.cat = data.cat.wq, conf=95)

```

## __Write Out The Results__

```{r}

write.csv(Water_Quality_Cat, "2020_SS_Cat.csv")
write.csv(Water_quality_Cont$CDF, file = '2020_SS_Cont_EstCDF.csv')
write.csv(Water_quality_Cont$Pct, file = '2020_SS_Cont_EstPCT.csv')

#### 
#######################################################################################
####
######################################################################################

```